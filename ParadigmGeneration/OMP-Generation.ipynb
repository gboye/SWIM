{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Générer les paradigmes morphomiques \n",
    "- changer les noms de sortie pour avoir moins de timestamps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "import pandas as pd\n",
    "import pickle, glob,re\n",
    "import itertools as it\n",
    "import networkx as nx\n",
    "import datetime as dt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug=False\n",
    "noDiff=True\n",
    "nbFormesPrint=False\n",
    "regroupeTirages=True\n",
    "phonologicalMap=\"-X\"\n",
    "cat=\"V\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dierese={\"j\":\"ij\", \"w\":\"uw\",\"H\":\"yH\",\"i\":\"ij\",\"u\":\"uw\",\"y\":\"yH\"}\n",
    "correctionsGlides={}\n",
    "correctionsHiatus={}\n",
    "preGlideFinal=set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutralisationsNORD=(u\"6û\",u\"9ê\")\n",
    "neutralisationsSUD=(u\"e2o\",u\"E9O\")\n",
    "if phonologicalMap==\"-N\":\n",
    "    neutralisations=neutralisationsNORD\n",
    "elif phonologicalMap==\"-S\":\n",
    "    neutralisations=neutralisationsSUD\n",
    "else:\n",
    "    neutralisations=(u\"\",u\"\")\n",
    "    phonologicalMap=(\"-X\")\n",
    "bdlexiqueIn = unicode(u\"èò\"+neutralisations[0])\n",
    "bdlexiqueNum = [ord(char) for char in bdlexiqueIn]\n",
    "neutreOut = unicode(u\"EO\"+neutralisations[1])\n",
    "neutralise = dict(zip(bdlexiqueNum, neutreOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoder(chaine,table=neutralise):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    else:\n",
    "        result=chaine\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkFrench(prononciation):\n",
    "    if prononciation:\n",
    "        result=recoder(prononciation)\n",
    "        m=re.match(ur\"^.*([^ieèEaOouy926êôâ])[jwH]$\",result)\n",
    "        if m:\n",
    "            print (\"pb avec un glide final\", prononciation)\n",
    "        m=re.match(ur\"(.*[ptkbdgfsSvzZ][rl])([jwH])(.*)\",result)\n",
    "        if m:\n",
    "            n=re.search(ur\"[ptkbdgfsSvzZ][rl](wa|Hi|wê)\",result)\n",
    "            if not n:\n",
    "                glide=m.group(2)\n",
    "                result=m.group(1)+dierese[glide]+m.group(3)\n",
    "        m=re.match(ur\"(.*)([iuy])([ieEaOouy].*)\",result)\n",
    "        if m:\n",
    "            glide=m.group(2)\n",
    "            result=m.group(1)+dierese[glide]+m.group(3)\n",
    "        result=result.replace(\"Jj\",\"J\")\n",
    "    else:\n",
    "        result=prononciation\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f6ze\n"
     ]
    }
   ],
   "source": [
    "print checkFrench(u\"f6ze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lireLexique(nomLexique):\n",
    "    with open(nomLexique, 'rb') as input:\n",
    "        lexique=pickle.load(input)\n",
    "    return lexique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexique2Paradigmes(lexique):\n",
    "    return pd.pivot_table(lexique, values='phono', index=['lexeme'], columns=['case'], aggfunc=lambda x: \",\".join(x)).reset_index().reindex()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nomFichierMorphomes=\"/Users/gilles/Box Sync/2015-Data/DerivationParadigmes/PG-Morphomes.tex\"\n",
    "listeTirages=glob.glob(\"/Users/gilles/Box Sync/2015-Data/DerivationParadigmes/Longitudinal*.pkl\")\n",
    "listeVHF=[u\"être\",\"avoir\",\"faire\",\"dire\",\"pouvoir\",\"aller\",\"voir\",\"savoir\",\"vouloir\",\"venir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "coulMF=[\"orange\",\"brown\",\"yellow\",\"lime\",\n",
    "          \"green\",\"teal\",\"lightgray\",\"pink\",\"cyan\",\"magenta\"]\n",
    "coulMT=[\"blue\",\"darkgray\",\"purple\",\"red\",\"olive\",\"violet\"]\n",
    "couleurCase={\n",
    "    \"pi2S\":\"orange\",\"pi3S\":\"orange\",\n",
    "    \"ii1S\":\"brown\",\"ii2S\":\"brown\",\"ii3S\":\"brown\",\"ii3P\":\"brown\",\n",
    "    \"fi1S\":\"yellow\",\"fi2P\":\"yellow\",\n",
    "    \"pc1S\":\"yellow\",\"pc2S\":\"yellow\",\"pc3S\":\"yellow\",\"pc3P\":\"yellow\",\n",
    "    \"fi2S\":\"lime\",\"fi3S\":\"lime\",\n",
    "    \"fi1P\":\"green\",\"fi3P\":\"green\",\n",
    "    \"ps1S\":\"teal\",\"ps2S\":\"teal\",\"ps3S\":\"teal\",\"ps3P\":\"teal\",\n",
    "    \"ai2S\":\"lightgray\",\"ai3S\":\"lightgray\",\"is3S\":\"lightgray\",\n",
    "    \"is1S\":\"pink\",\"is2S\":\"pink\",\"is3P\":\"pink\",\n",
    "    \"ppMS\":\"cyan\",\"ppMP\":\"cyan\",\n",
    "    \"ppFS\":\"magenta\",\"ppFP\":\"magenta\"\n",
    "            }\n",
    "listLimites=[2,8,32,128,512]\n",
    "listLimCoul=[\"red\",\"pink\",\"orange\",\"green\",\"teal\",\"white\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomFichierMorphomes=\"/Volumes/gilles/Transfert/Copies-iMac-GB/2015-Data/Longitudinales/PG-Longitudinal-Morphomes.tex\"\n",
    "nomFichierMorphomes=\"/Volumes/gilles/Transfert/Copies-iMac-GB/2015-Data/LongitudinalesRnd/PG-Longitudinal-Morphomes.tex\"\n",
    "nomFichierMorphomes=\"/Volumes/gilles/Transfert/Copies-iMac-GB/2015-Data/lexique3/PG-Longitudinal-Morphomes.tex\"\n",
    "#listeTirages=glob.glob(\"/Volumes/gilles/Transfert/Copies-iMac-GB/2015-Data/Longitudinales/Longitudinal-11[5-9]*.pkl\")\n",
    "#listeTirages+=glob.glob(\"/Volumes/gilles/Transfert/Copies-iMac-GB/2015-Data/Longitudinales/Longitudinal-12[0-9]*.pkl\")\n",
    "listeTirages=glob.glob(\"/Volumes/gilles/Transfert/Copies-iMac-GB/2015-Data/LongitudinalesRnd/Longitudinal-[12][0-9]*.pkl\")\n",
    "listeTirages=glob.glob(\"/Volumes/gilles/Transfert/Copies-iMac-GB/2015-Data/lexique3/Longitudinal*.pkl\")\n",
    "listeTirages=glob.glob(\"/Volumes/gilles/Transfert/Copies-iMac-GB/2015-Data/lexique3/Longitudinal*01*.pkl\")\n",
    "listeTirages=glob.glob(\"/Volumes/gilles/Transfert/Copies-iMac-GB/2015-Data/lexique3/AltLexique3/Longitudinal*00*.pkl\")\n",
    "listeVHF=[u\"être\",\"avoir\",\"faire\",\"dire\",\"pouvoir\",\"aller\",\"voir\",\"savoir\",\"vouloir\",\"venir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Volumes/gilles/Transfert/Copies-iMac-GB/2015-Data/lexique3/AltLexique3/Longitudinal-AltLexique3-00-T150000000-F73294.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listeTirages"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "coulMF=[\"orange\",\"brown\",\"yellow\",\"lime\",\n",
    "          \"green\",\"teal\",\"lightgray\",\"pink\",\"cyan\",\"magenta\"]\n",
    "coulMT=[\"blue\",\"darkgray\",\"purple\",\"red\",\"olive\",\"violet\"]\n",
    "couleurCase={\n",
    "    \"ms\":\"orange\",\"mp\":\"yellow\",\n",
    "    \"fs\":\"green\",\"fp\":\"green\"\n",
    "            }\n",
    "listLimites=[2,8,32,128,512]\n",
    "listLimCoul=[\"red\",\"pink\",\"orange\",\"green\",\"teal\",\"white\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nomFichierMorphomes=\"/Users/gilles/Box Sync/2015-Data/PG-GermanVerbs-Morphomes.tex\"\n",
    "listeTirages=glob.glob(\"/Users/gilles/Box Sync/2015-Data/German/German*-MSP.pkl\")\n",
    "listeVHF=[u\"être\",\"avoir\",\"faire\",\"dire\",\"pouvoir\",\"aller\",\"voir\",\"savoir\",\"vouloir\",\"venir\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "coulMF=[\"orange\",\"brown\",\"yellow\",\"lime\",\n",
    "          \"green\",\"teal\",\"lightgray\",\"pink\",\"cyan\",\"magenta\"]\n",
    "coulMT=[\"blue\",\"darkgray\",\"purple\",\"red\",\"olive\",\"violet\",\"red\",\"pink\",\"orange\",\"green\",\"teal\",\"white\"]\n",
    "couleurCase={\n",
    "    \"ms\":\"orange\",\"mp\":\"yellow\",\n",
    "    \"fs\":\"green\",\"fp\":\"green\"\n",
    "            }\n",
    "listLimites=[2,8,32,128,512]\n",
    "listLimCoul=[\"red\",\"pink\",\"orange\",\"green\",\"teal\",\"white\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiragesNom(nom):\n",
    "    result=[tirage for tirage in listeTirages if nom in tirage]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbFormesEchantillons(nom):\n",
    "    print nom\n",
    "    for tirage in tiragesNom(nom):\n",
    "        sample=lireLexique(tirage)\n",
    "        print sample[sample[\"tir1\"]>0][\"tir1\"].count(),\n",
    "        print sample[sample[\"tir1\"]>0][\"tir1\"].sum(),\n",
    "        print tirage"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "listeTirages200=tiragesNom(\"200Mo\")\n",
    "listeTirages20=tiragesNom(\"20Mo\")\n",
    "#len(listeTirages200)\n",
    "listeTirages1=tiragesNom(\"1Mo\")\n",
    "listeTirages50k=tiragesNom(\"50Ko\")\n",
    "listeTirages100k=tiragesNom(\"100Ko\")\n",
    "listeTirages20000k=tiragesNom(\"20000Ko\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "listeTirages20"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "listeAdHoc=[listeTirages100k[-1],listeTirages1[0],listeTirages20[0],listeTirages200[0]]\n",
    "listeAdHoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFormNumbers(paradigme):\n",
    "    dictNumbers={}\n",
    "    cases=[c for c in paradigmes.columns.tolist() if c!=\"lexeme\"]\n",
    "    for case in cases:\n",
    "        dictNumbers[case]=paradigme[case].count()\n",
    "    return dictNumbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceTrad(el,traductions):\n",
    "    if traductions[el]==el:\n",
    "        return el\n",
    "    else:\n",
    "        return reduceTrad(traductions[el],traductions)\n",
    "    \n",
    "def defParadigme(paradigmes):\n",
    "    syncretisms=[]\n",
    "    cases=[c for c in paradigmes.columns.tolist() if c!=\"lexeme\"]\n",
    "    for (c1,c2) in it.combinations(cases, 2):\n",
    "        c1Val=paradigmes[c1].notnull()\n",
    "        c2Val=paradigmes[c2].notnull()\n",
    "        c1Sur=paradigmes[c1].str.contains(\",\")\n",
    "        c2Sur=paradigmes[c2].str.contains(\",\")\n",
    "        l1=len(paradigmes[paradigmes[c1].notnull()])\n",
    "        l2=len(paradigmes[paradigmes[c2].notnull()])\n",
    "        paire=paradigmes[c1Val & c2Val & (paradigmes[c1]!=paradigmes[c2])][[c1,c2]]\n",
    "        lenDiff=len(paire[~paire[c1].str.contains(\",\") & ~paire[c2].str.contains(\",\")])\n",
    "        if lenDiff>0:\n",
    "            if debug:\n",
    "                print u\"%s ≠ %s\"%(c1,c2)\n",
    "                print \"différence\",lenDiff\n",
    "                if lenDiff<12:\n",
    "                    print paire\n",
    "        else:\n",
    "            surAbondant=paire[paire[c1].str.contains(\",\") | paire[c2].str.contains(\",\")]\n",
    "#            print \"--------------------------------\"\n",
    "            if len(surAbondant)==0:\n",
    "#                print u\"%s = %s\"%(c1,c2) \n",
    "                syncretisms.append(u\"%s = %s\"%(c1,c2))\n",
    "            else:\n",
    "                compatible=True\n",
    "                for index,row in surAbondant.iterrows():\n",
    "                    if \",\" in row[c1]:\n",
    "                        if \",\" in row[c2]:\n",
    "                            if row[c1]!=row[c2]:\n",
    "                                compatible=False\n",
    "                        else:\n",
    "                            if not row[c2] in row[c1].split(\",\"):\n",
    "                                compatible=False\n",
    "                    else:\n",
    "                        if not row[c1] in row[c2].split(\",\"):\n",
    "                            compatible=False\n",
    "                if compatible:\n",
    "#                    print u\"%s = %s\"%(c1,c2)\n",
    "                    syncretisms.append(u\"%s = %s\"%(c1,c2))\n",
    "                else:\n",
    "                    print u\"%s ≠ %s\"%(c1,c2)\n",
    "                    print surAbondant\n",
    "\n",
    "    reductionParadigme={c:c for c in cases}\n",
    "    for syncretism in syncretisms:\n",
    "        c1,c2=syncretism.split(\" = \")\n",
    "        removeC=max(c1,c2)\n",
    "        keyC=min(c1,c2)\n",
    "        if removeC in reductionParadigme:\n",
    "            if keyC in reductionParadigme:\n",
    "                key=min(reductionParadigme[keyC],reductionParadigme[removeC])\n",
    "            else:\n",
    "                key=min(keyC,reductionParadigme[removeC])\n",
    "        else:\n",
    "            if keyC in reductionParadigme:\n",
    "                key=reductionParadigme[keyC]\n",
    "            else:\n",
    "                key=keyC\n",
    "        reductionParadigme[removeC]=key\n",
    "        reductionParadigme[keyC]=key\n",
    "\n",
    "    for el in reductionParadigme:\n",
    "        reductionParadigme[el]=reduceTrad(el,reductionParadigme)\n",
    "\n",
    "    paradigmeReduit = {}\n",
    "    for k, v in reductionParadigme.iteritems():\n",
    "        paradigmeReduit[v] = paradigmeReduit.get(v, [])\n",
    "        paradigmeReduit[v].append(k)\n",
    "    print \"syncrétismes\",len(paradigmeReduit), sorted(paradigmeReduit.keys())\n",
    "    print paradigmeReduit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findClique(cliques,remElement=\"node\"):\n",
    "    pNodes=set()\n",
    "\n",
    "    sCliques=sorted(cliques, key=len, reverse=True)\n",
    "\n",
    "    cliqueFound=sorted(sCliques[0])\n",
    "    pNodes=pNodes|set(sCliques[0])\n",
    "\n",
    "    if remElement==\"clique\":\n",
    "        removeCliques=[]\n",
    "        for clique in sCliques:\n",
    "            sClique=set(clique)\n",
    "            if set.intersection(pNodes,sClique):\n",
    "                removeCliques.append(clique)\n",
    "        for clique in removeCliques:\n",
    "            sCliques.remove(clique)\n",
    "    elif remElement==\"node\":\n",
    "        newCliques=[]\n",
    "        for clique in sCliques:\n",
    "            sClique=set(clique)\n",
    "            diffClique=list(sClique-set.intersection(pNodes,sClique))\n",
    "            if diffClique:\n",
    "                newCliques.append(diffClique)               \n",
    "#            print \"sortie\",newCliques\n",
    "        sCliques=sorted(newCliques,key=len,reverse=True)\n",
    "    else:\n",
    "        print \"remElement non prévu\"\n",
    "    return (cliqueFound,sCliques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPartition(syncretismes):\n",
    "    g=nx.Graph()\n",
    "    for node in list(lexique[lexique[\"tir1\"]>0][\"case\"].unique()):\n",
    "        g.add_node(node)\n",
    "    for syncretisme in syncretismes:\n",
    "        c1,c2=syncretisme.split(\" = \")\n",
    "        g.add_edge(c1,c2)\n",
    "    cliques.extend(list(nx.find_cliques(g)))\n",
    "    sCliques=sorted(cliques, key=len, reverse=True)\n",
    "    foundCliques=[]\n",
    "    while sCliques:\n",
    "        foundClique,sCliques=findClique(sCliques)\n",
    "        foundCliques.append(foundClique)\n",
    "    foundNodes=set(n for l in foundCliques for n in l )\n",
    "    missingNodes=[[n] for n in g.nodes() if not n in foundNodes]\n",
    "    partition=foundCliques+missingNodes\n",
    "    dictPartition={l[0]:l for l in partition}\n",
    "    return dictPartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawPartition(dictPartition):\n",
    "    g=nx.DiGraph()\n",
    "    g.add_node(\"paradigme\",color=\"red\")\n",
    "    for numMorphome,morphome in enumerate(dictPartition):\n",
    "        g.add_node(\"M%02d\"%numMorphome,color=\"blue\")\n",
    "        g.add_edge(\"paradigme\",\"M%02d\"%numMorphome)\n",
    "        for case in dictPartition[morphome]:\n",
    "            g.add_edge(\"M%02d\"%numMorphome,case)\n",
    "    graphs.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findColours(dictPartition,debug=False):\n",
    "    def assignColour(listMorphome,morphColour):\n",
    "        for m in listMorphome:\n",
    "            if not m in dictColours:\n",
    "                dictColours[m]=morphColour\n",
    "            else:\n",
    "                print \"conflit sur %s entre %s et %s\"%(m,dictColours[m],morphColour)\n",
    "\n",
    "    dictColours={}\n",
    "    iCoul=0\n",
    "    for morphome in dictPartition:\n",
    "        listMorphome=dictPartition[morphome]\n",
    "        lenMorphome=len(listMorphome)\n",
    "        if lenMorphome>1:\n",
    "            if debug: print lenMorphome,listMorphome,\n",
    "            if morphome in couleurCase:\n",
    "                if debug: print couleurCase[morphome]\n",
    "                morphColour=couleurCase[morphome]\n",
    "            else:\n",
    "                noCoul=True\n",
    "                for el in listMorphome:\n",
    "                    if el in couleurCase:\n",
    "                        if debug: print couleurCase[el]\n",
    "                        morphColour=couleurCase[el]\n",
    "                        noCoul=False\n",
    "                        break\n",
    "                if noCoul:\n",
    "                    if debug: print \"autre\",coulMT[iCoul]\n",
    "                    morphColour=coulMT[iCoul]\n",
    "                    iCoul+=1\n",
    "        else:\n",
    "            morphColour=\"white\"\n",
    "        assignColour(listMorphome,morphColour)\n",
    "    return dictColours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTabular(dictColours,title=\"\",coulLim=False, cat=\"V\"):\n",
    "    tabular=[]\n",
    "    def makeLine6(tenseCode):\n",
    "        line=[]\n",
    "        for person in [per+nb for nb in [\"S\",\"P\"] for per in [\"1\",\"2\",\"3\"]]:\n",
    "            case=tenseCode+person\n",
    "            if case in dictColours:\n",
    "                line.append(r\"\\cellcolor{%s}%s\"%(dictColours[case],case))\n",
    "            else:\n",
    "                line.append(r\"\\cellcolor{%s}%s\"%(\"black\",case))\n",
    "        return r\" & \".join(line)+r\"\\\\\"\n",
    "\n",
    "    def makeLine3(tenseCode):\n",
    "        line=[]\n",
    "        for person in [per+nb for nb in [\"S\",\"P\"] for per in [\"1\",\"2\",\"3\"]]:\n",
    "            if person in [\"2S\",\"1P\",\"2P\"]:\n",
    "                case=tenseCode+person\n",
    "                if case in dictColours:\n",
    "                    line.append(r\"\\cellcolor{%s}%s\"%(dictColours[case],case))\n",
    "                else:\n",
    "                    line.append(r\"\\cellcolor{%s}%s\"%(\"black\",case))\n",
    "#                line.append(r\"\\cellcolor{%s}%s\"%(dictColours[case],case))\n",
    "            else:\n",
    "                line.append(r\"---\")\n",
    "        return r\" & \".join(line)+r\"\\\\\"\n",
    "    \n",
    "    def makeLineNF():\n",
    "        line=[]\n",
    "        for case in [\"inf\",\"pP\",\"ppMS\",\"ppMP\",\"ppFS\",\"ppFP\"]:\n",
    "            if case in dictColours:\n",
    "                line.append(r\"\\cellcolor{%s}%s\"%(dictColours[case],case))\n",
    "            else:\n",
    "                line.append(r\"\\cellcolor{%s}%s\"%(\"black\",case))\n",
    "#            line.append(r\"\\cellcolor{%s}%s\"%(dictColours[case],case))\n",
    "        return r\" & \".join(line)+r\"\\\\\"\n",
    "\n",
    "    def makeLineMF(nombre):\n",
    "        line=[]\n",
    "        for genre in \"mf\":\n",
    "            case=genre+nombre\n",
    "            if case in dictColours:\n",
    "                line.append(r\"\\cellcolor{%s}%s\"%(dictColours[case],case))\n",
    "            else:\n",
    "                line.append(r\"\\cellcolor{%s}%s\"%(\"black\",case))\n",
    "        return r\" & \".join(line)+r\"\\\\\"\n",
    "    \n",
    "    def makeLineCoulLim():\n",
    "        line=[]\n",
    "        for numLimite,limite in enumerate(listLimites):\n",
    "            line.append(r\"\\cellcolor{%s}%s\"%(listLimCoul[numLimite],\"$<$\"+str(limite)))\n",
    "        return r\"\\hline\\hline \"+r\" & \".join(line)+r\"\\\\\"\n",
    "        \n",
    "    if cat==\"V\":\n",
    "        top=[\n",
    "            r\"\\begin{center}\",\n",
    "            r\"\\begin{tabular}{cccccc}\",\n",
    "            r\"\\hline\"\n",
    "            ]\n",
    "        bottom=[\n",
    "            r\"\\hline\",\n",
    "            r\"\\end{tabular}\\\\\",\n",
    "            title,\n",
    "            r\"\\end{center}\",\n",
    "            r\"\\bigskip\",\n",
    "            r\"\"\n",
    "            ]\n",
    "        tabular.append(\"\\n\".join(top))\n",
    "        for tenseCode in [\"pi\",\"ii\",\"fi\",\"pc\", \"ps\",\"ai\", \"is\"]:\n",
    "            tabular.append(makeLine6(tenseCode))\n",
    "        tabular.append(makeLine3(\"pI\"))\n",
    "        tabular.append(makeLineNF())\n",
    "    elif cat==\"A\":\n",
    "        top=[\n",
    "            r\"\\begin{center}\",\n",
    "            r\"\\begin{tabular}{cc}\",\n",
    "            r\"\\hline\"\n",
    "            ]\n",
    "        bottom=[\n",
    "            r\"\\hline\",\n",
    "            r\"\\end{tabular}\\\\\",\n",
    "            title,\n",
    "            r\"\\end{center}\",\n",
    "            r\"\\bigskip\",\n",
    "            r\"\"\n",
    "            ]\n",
    "        tabular.append(\"\\n\".join(top))\n",
    "        for number in \"sp\":\n",
    "            tabular.append(makeLineMF(number))\n",
    "    if coulLim:\n",
    "        tabular.append(makeLineCoulLim())\n",
    "    tabular.append(\"\\n\".join(bottom))\n",
    "    return \"\\n\".join(tabular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caseEgalite(c1,c2,debug=False):\n",
    "    c1Val=paradigmes[c1].notnull()\n",
    "    c2Val=paradigmes[c2].notnull()\n",
    "    c1Sur=paradigmes[c1].str.contains(\",\")\n",
    "    c2Sur=paradigmes[c2].str.contains(\",\")\n",
    "    l1=len(paradigmes[paradigmes[c1].notnull()])\n",
    "    l2=len(paradigmes[paradigmes[c2].notnull()])\n",
    "    egalPaire=paradigmes[c1Val & c2Val & (paradigmes[c1]==paradigmes[c2])][[c1,c2]]\n",
    "    diffPaire=paradigmes[c1Val & c2Val & (paradigmes[c1]!=paradigmes[c2])][[c1,c2]]\n",
    "    lenDiff=len(diffPaire[~diffPaire[c1].str.contains(\",\") & ~diffPaire[c2].str.contains(\",\")])\n",
    "    if debug:\n",
    "        print egalPaire\n",
    "        print diffPaire\n",
    "        print lenDiff\n",
    "    if lenDiff>0:\n",
    "        return False\n",
    "        if debug:\n",
    "            print u\"%s ≠ %s\"%(c1,c2)\n",
    "            print \"différence\",lenDiff\n",
    "            if lenDiff<12:\n",
    "                print diffPaire\n",
    "    else:\n",
    "        surAbondant=diffPaire[diffPaire[c1].str.contains(\",\") | diffPaire[c2].str.contains(\",\")]\n",
    "        if len(surAbondant)==0:\n",
    "            if len(egalPaire)>0 or noDiff:\n",
    "                if debug: print u\"%s = %s\"%(c1,c2), len(egalPaire)\n",
    "                return True\n",
    "        else:\n",
    "            compatible=True\n",
    "            egalCount=0\n",
    "            for index,row in surAbondant.iterrows():\n",
    "                if \",\" in row[c1]:\n",
    "                    if \",\" in row[c2]:\n",
    "                        setC1=set(row[c1].split(\",\"))\n",
    "                        setC2=set(row[c2].split(\",\"))\n",
    "                        print setC1&setC2\n",
    "                        if not setC1&setC2:\n",
    "                            compatible=False\n",
    "                            break\n",
    "                        else:\n",
    "                            egalCount+=1\n",
    "                    else:\n",
    "                        if not row[c2] in row[c1].split(\",\"):\n",
    "                            compatible=False\n",
    "                            break\n",
    "                        else:\n",
    "                            egalCount+=1\n",
    "                else:\n",
    "                    if not row[c1] in row[c2].split(\",\"):\n",
    "                        compatible=False\n",
    "                        break\n",
    "                    else:\n",
    "                        egalCount+=1\n",
    "            if compatible:\n",
    "                if debug: print u\"%s = %s\"%(c1,c2), len(egalPaire), egalCount\n",
    "                return True\n",
    "            else:\n",
    "                if debug: print u\"%s ≠ %s\"%(c1,c2)\n",
    "                if debug: print surAbondant\n",
    "                return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defParadigme(paradigmes,debug=False):\n",
    "    syncretisms=[]\n",
    "\n",
    "    cases=[c for c in paradigmes.columns.tolist() if c!=\"lexeme\"]\n",
    "    if debug: print \"%d cases :\"%len(cases),\", \".join(cases)\n",
    "    for (c1,c2) in it.combinations(cases, 2):\n",
    "        if caseEgalite(c1,c2):\n",
    "            syncretisms.append(u\"%s = %s\"%(c1,c2))\n",
    "    dictPartition=findPartition(syncretisms)\n",
    "    itemizeLines.append(\"%d morphomes\"%len(dictPartition))\n",
    "    for key in sorted(dictPartition):\n",
    "        if debug: print \"%s: %s,\" % (key, dictPartition[key]),\n",
    "    if debug: print\n",
    "    drawPartition(dictPartition)\n",
    "    return(dictPartition)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def pivotLexique(lexique,debug=False):\n",
    "    paradigmes=pd.pivot_table(lexique[lexique[\"tir1\"]>0], values='phono', index=['lexeme'], columns=['case'], aggfunc=lambda x: \",\".join(x)).reset_index().reindex()\n",
    "    return defParadigme(paradigmes,debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeItemize(itemizeLines):\n",
    "    lines=[]\n",
    "    lines.append(r\"\\begin{itemize}\")\n",
    "    for line in itemizeLines:\n",
    "        lines.append(r\"\\item \"+line)\n",
    "    lines.append(r\"\\end{itemize}\")\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findNumberColour(dictNumbers):\n",
    "    result={}\n",
    "    for case in dictNumbers:\n",
    "        if dictNumbers[case]<listLimites[0]:\n",
    "            result[case]=listLimCoul[0]\n",
    "        elif dictNumbers[case]<listLimites[1]:\n",
    "            result[case]=listLimCoul[1]\n",
    "        elif dictNumbers[case]<listLimites[2]:\n",
    "            result[case]=listLimCoul[2]\n",
    "        elif dictNumbers[case]<listLimites[3]:\n",
    "            result[case]=listLimCoul[3]\n",
    "        elif dictNumbers[case]<listLimites[4]:\n",
    "            result[case]=listLimCoul[4]\n",
    "        else:\n",
    "            result[case]=listLimCoul[5]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regroupeLexique(dictPartition,lexique):\n",
    "    lexiqueRegroupe=lexique.copy()\n",
    "    for p in dictPartition:\n",
    "        lCases=dictPartition[p]\n",
    "        lexiqueRegroupe.loc[lexiqueRegroupe[\"case\"].isin(lCases),\"morphome\"]=\"/\".join(lCases)\n",
    "        lexiqueRegroupe.loc[lexiqueRegroupe[\"case\"].isin(lCases),\"case\"]=p\n",
    "    return lexiqueRegroupe.groupby([\"lexeme\",\"phono\",\"case\",\"morphome\"]).agg({\"freq\":np.sum, \"tir1\":np.sum}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tableauPaires(paradigme):\n",
    "    table=pd.DataFrame(columns=[\"ligne\",\"colonne\",\"nbPaires\"])\n",
    "    refCases=paradigme.columns.tolist()\n",
    "    refCases.remove(\"lexeme\")\n",
    "    for n,paire in enumerate(it.combinations_with_replacement(refCases,2)):\n",
    "        if paire[0] in paradigme.columns and paire[1] in paradigme.columns:\n",
    "            nbPaires=len(paradigme[[paire[0],paire[1]]].dropna())\n",
    "        else:\n",
    "            nbPaires=0\n",
    "        table.loc[2*n]=[paire[0],paire[1],nbPaires]\n",
    "        table.loc[2*n+1]=[paire[1],paire[0],nbPaires]\n",
    "    tableau=table.pivot_table(index=\"ligne\",columns=[\"colonne\"],aggfunc='first') # aggfunc='first' évite l'erreur avec les duplicates\n",
    "    return tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([u'EtEj', u'EtE'])\n"
     ]
    }
   ],
   "source": [
    "graphs=[]\n",
    "latexLines=[]\n",
    "pairesTableaux=[]\n",
    "#for nomLexique in sorted(listeTirages100k):\n",
    "for nLexique,nomLexique in enumerate(listeTirages):\n",
    "    lexique=lireLexique(nomLexique)\n",
    "    lexique[\"phono\"]=lexique[\"phono\"].apply(checkFrench)\n",
    "    if not 'tir1' in lexique.columns:\n",
    "        lexique[\"tir1\"]=1\n",
    "    if not 'freq' in lexique.columns:\n",
    "        lexique[\"freq\"]=1\n",
    "    lexique1=lexique[lexique[\"tir1\"]>0]\n",
    "    taille=lexique1[\"tir1\"].count()\n",
    "    itemizeLines=[]\n",
    "    latexLines.append(nomLexique.split(\"/\")[-1])\n",
    "    itemizeLines.append(\"%d formes\"%taille)\n",
    "    itemizeLines.append(\"%d tirages\"%lexique1[\"tir1\"].sum())\n",
    "    paradigmes=lexique2Paradigmes(lexique1)\n",
    "    tableauOrigine=tableauPaires(paradigmes)\n",
    "    dictNumbers=findFormNumbers(paradigmes)\n",
    "    dictFormNumbers=findNumberColour(dictNumbers)\n",
    "\n",
    "    syncretisms=[]\n",
    "    cliques=[]\n",
    "\n",
    "    dictPartition=defParadigme(paradigmes)\n",
    "    if regroupeTirages and noDiff:\n",
    "        lexiqueRegroupe=regroupeLexique(dictPartition,lexique1)\n",
    "        paradigmesRegroupe=lexique2Paradigmes(lexiqueRegroupe)\n",
    "        tableauRegroupe=tableauPaires(paradigmesRegroupe)\n",
    "\n",
    "        tableauOrigine.to_csv(nomLexique.replace(\".pkl\",\"-%s%d-Separe.csv\"%(dt.datetime.now().strftime(\"%y%m%d-%H%M\"),nLexique)),sep=\";\",encoding=\"utf8\")\n",
    "        tableauRegroupe.to_csv(nomLexique.replace(\".pkl\",\"-%s%d-Groupe.csv\"%(dt.datetime.now().strftime(\"%y%m%d-%H%M\"),nLexique)),sep=\";\",encoding=\"utf8\")\n",
    "\n",
    "        pairesTableaux.append((tableauOrigine,tableauRegroupe))\n",
    "        nomLexiqueRegroupe=nomLexique.replace(\".pkl\",phonologicalMap+\"-%s-Morphomes.pkl\"%dt.datetime.now().strftime(\"%y%m%d-%H%M\"))\n",
    "        if nomLexique==nomLexiqueRegroupe:\n",
    "            print u\"pb avec le nom du fichier pour les tirages regroupés\"\n",
    "        else:\n",
    "            with open(nomLexiqueRegroupe,\"wb\") as output:\n",
    "                pickle.dump(lexiqueRegroupe, output, pickle.HIGHEST_PROTOCOL)\n",
    "    dictColours=findColours(dictPartition)\n",
    "    latexLines.append(makeItemize(itemizeLines))\n",
    "    latexLines.append(makeTabular(dictColours,title=\"Morphomes\",cat=cat))\n",
    "    if nbFormesPrint:\n",
    "        latexLines.append(makeTabular(dictFormNumbers,title=\"Nombre de formes\",coulLim=True,cat=cat))\n",
    "if noDiff:\n",
    "    nomFichierSortie=nomFichierMorphomes.replace(\".tex\",phonologicalMap+\"-%s-NoDiff.tex\"%dt.datetime.now().strftime(\"%y%m%d-%H%M\"))\n",
    "else:\n",
    "    nomFichierSortie=nomFichierMorphomes.replace(\".tex\",phonologicalMap+\"-%s-Diff.tex\"%dt.datetime.now().strftime(\"%y%m%d-%H%M\"))\n",
    "with open(nomFichierSortie,\"w\") as output:\n",
    "    output.write(\"\\n\".join(latexLines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculs pour le lexique complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/Users/gilles/Box Sync/2015-Data/MGC-160104-Verbes2.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-3d5f02905620>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlexiquePrefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"MGC-160104\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnomLexiqueBase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/Users/gilles/Box Sync/2015-Data/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlexiquePrefix\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-Verbes2.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnomLexiqueBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mlexiqueBase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/Users/gilles/Box Sync/2015-Data/MGC-160104-Verbes2.pkl'"
     ]
    }
   ],
   "source": [
    "lexiquePrefix=\"MGC-160104\"\n",
    "nomLexiqueBase=\"/Users/gilles/Box Sync/2015-Data/\"+lexiquePrefix+'-Verbes2.pkl'\n",
    "with open(nomLexiqueBase, 'rb') as input:\n",
    "    lexiqueBase = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lexiqueBase[\"freqcum\"]= (lexiqueBase[\"freq\"].cumsum()*1000).astype(int)\n",
    "del lexiqueBase[\"ext\"]\n",
    "del lexiqueBase[\"cs\"]\n",
    "del lexiqueBase[\"ms\"]\n",
    "del lexiqueBase[\"vs\"]\n",
    "del lexiqueBase[\"prob\"]\n",
    "lexiqueBase[\"tir1\"]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "graphs=[]\n",
    "latexLines=[]\n",
    "pairesTableaux=[]\n",
    "lexique=lexiqueBase\n",
    "lexique[\"phono\"]=lexique[\"phono\"].apply(checkFrench)\n",
    "lexique1=lexique[lexique[\"tir1\"]>0]\n",
    "taille=lexique1[\"tir1\"].count()\n",
    "itemizeLines=[]\n",
    "latexLines.append(nomLexiqueBase.split(\"/\")[-1])\n",
    "itemizeLines.append(\"%d formes\"%taille)\n",
    "itemizeLines.append(\"%d tirages\"%lexique1[\"tir1\"].sum())\n",
    "paradigmes=lexique2Paradigmes(lexique1)\n",
    "tableauBaseOrigine=tableauPaires(paradigmes)\n",
    "dictNumbers=findFormNumbers(paradigmes)\n",
    "dictFormNumbers=findNumberColour(dictNumbers)\n",
    "\n",
    "syncretisms=[]\n",
    "cliques=[]\n",
    "\n",
    "dictPartition=defParadigme(paradigmes)\n",
    "if regroupeTirages and noDiff:\n",
    "    lexiqueBaseRegroupe=regroupeLexique(dictPartition,lexique1)\n",
    "    paradigmesBaseRegroupe=lexique2Paradigmes(lexiqueBaseRegroupe)\n",
    "    tableauBaseRegroupe=tableauPaires(paradigmesBaseRegroupe)\n",
    "\n",
    "    tableauBaseOrigine.to_csv(nomLexiqueBase.replace(\".pkl\",\"-%s-Complet-Separe.csv\"%(dt.datetime.now().strftime(\"%y%m%d-%H%M\"))),sep=\";\",encoding=\"utf8\")\n",
    "    tableauBaseRegroupe.to_csv(nomLexiqueBase.replace(\".pkl\",\"-%s-Complet-Groupe.csv\"%(dt.datetime.now().strftime(\"%y%m%d-%H%M\"))),sep=\";\",encoding=\"utf8\")\n",
    "\n",
    "    pairesTableaux.append((tableauBaseOrigine,tableauBaseRegroupe))\n",
    "    nomLexiqueBaseRegroupe=nomLexiqueBase.replace(\".pkl\",phonologicalMap+\"-%s-Morphomes.pkl\"%dt.datetime.now().strftime(\"%y%m%d-%H%M\"))\n",
    "    if nomLexiqueBase==nomLexiqueBaseRegroupe:\n",
    "        print u\"pb avec le nom du fichier pour les tirages regroupés\"\n",
    "    else:\n",
    "        with open(nomLexiqueBaseRegroupe,\"wb\") as output:\n",
    "            pickle.dump(lexiqueBaseRegroupe, output, pickle.HIGHEST_PROTOCOL)\n",
    "dictColours=findColours(dictPartition)\n",
    "latexLines.append(makeItemize(itemizeLines))\n",
    "latexLines.append(makeTabular(dictColours,title=\"Morphomes\",cat=cat))\n",
    "if nbFormesPrint:\n",
    "    latexLines.append(makeTabular(dictFormNumbers,title=\"Nombre de formes\",coulLim=True,cat=cat))\n",
    "if noDiff:\n",
    "    nomFichierSortie=nomFichierMorphomes.replace(\".tex\",phonologicalMap+\"-%s-NoDiff.tex\"%dt.datetime.now().strftime(\"%y%m%d-%H%M\"))\n",
    "else:\n",
    "    nomFichierSortie=nomFichierMorphomes.replace(\".tex\",phonologicalMap+\"-%s-Diff.tex\"%dt.datetime.now().strftime(\"%y%m%d-%H%M\"))\n",
    "with open(nomFichierSortie,\"w\") as output:\n",
    "    output.write(\"\\n\".join(latexLines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "caseEgalite(\"pi2S\",\"pi3S\",debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for nEchant,(tableau1,tableau2) in enumerate(pairesTableaux):\n",
    "    tableau1.to_csv(nomLexique.replace(\".pkl\",\"%d-Separe.csv\"%nEchant),sep=\";\",encoding=\"utf8\")\n",
    "    tableau2.to_csv(nomLexique.replace(\".pkl\",\"%d-Groupe.csv\"%nEchant),sep=\";\",encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "try:\n",
    "    import pygraphviz\n",
    "    from networkx.drawing.nx_agraph import write_dot\n",
    "    print(\"using package pygraphviz\")\n",
    "except ImportError:\n",
    "    try:\n",
    "        import pydotplus\n",
    "        from networkx.drawing.nx_pydot import write_dot\n",
    "        print(\"using package pydotplus\")\n",
    "    except ImportError:\n",
    "        print()\n",
    "        print(\"Both pygraphviz and pydotplus were not found \")\n",
    "        print(\"see http://networkx.github.io/documentation\"\n",
    "              \"/latest/reference/drawing.html for info\")\n",
    "        print()\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "G=graphs[0]\n",
    "#pos = \n",
    "#nx.draw(G,pos=nx.layout.fruchterman_reingold_layout(G,scale=20))\n",
    "for numG,G in enumerate(graphs):\n",
    "    write_dot(G,\"test%02d.dot\"%numG)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pdLexiqueRegroupe=regroupeLexique(dictPartition,lexique1)\n",
    "pdLexiqueRegroupe\n",
    "pdParadigmeRegroupe=pd.pivot_table(pdLexiqueRegroupe, values='phono', index=['lexeme'], columns=['case'], aggfunc=lambda x: \",\".join(x))\n",
    "pdParadigmeRegroupe.to_dict(orient=\"index\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pdLexiqueRegroupe[pdLexiqueRegroupe[\"lexeme\"]==u\"abaisser\"][[\"phono\",\"case\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lexiqueRegroupe[[\"case\",\"morphome\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7",
   "language": "python",
   "name": "py2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
